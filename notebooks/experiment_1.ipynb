{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persyaratan Teknis:\n",
    "- Gunakan minimal dua operator pengolahan citra dasar (misalnya,\n",
    "Gaussian blur, edge detection) untuk meningkatkan kualitas data.\n",
    "- Implementasikan minimal dua metode detektor atau deskriptor fitur lokal\n",
    "(misalnya, SIFT, SURF, ORB).\n",
    "- Buat sistem untuk menemukan korespondensi antara beberapa citra\n",
    "(misalnya, menggunakan keypoints matching) dan menerapkannya dalam\n",
    "pengenalan.\n",
    "- Bangun sistem pengenalan berbasis fitur yang mampu mengklasifikasikan\n",
    "atau mengidentifikasi objek dalam citra secara otomatis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report \n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = Path('../dataset/Data')\n",
    "\n",
    "train_paths = pd.read_csv(DATASET_PATH / \"train_paths.csv\")\n",
    "valid_paths = pd.read_csv(DATASET_PATH / \"valid_paths.csv\")\n",
    "test_paths = pd.read_csv(DATASET_PATH / \"test_paths.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    # Apply Gaussian Blur\n",
    "    blurred = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "    # Apply Edge Detection (Canny)\n",
    "    edges = cv2.Canny(blurred, 100, 200)\n",
    "    return edges\n",
    "\n",
    "def load_images(annotation):\n",
    "    images = []\n",
    "    heights = []\n",
    "    widhts = []\n",
    "    for path in annotation['path'].values:\n",
    "        image = cv2.imread(path, flags=cv2.IMREAD_GRAYSCALE)\n",
    "        image = cv2.resize(image, (516, 382))\n",
    "        image = preprocess_image(image)\n",
    "        images.append(image)\n",
    "        heights.append(np.shape(image)[0])\n",
    "        widhts.append(np.shape(image)[1])\n",
    "    # print((np.min(heights) - np.max(heights)) // 2)\n",
    "    # print((np.min(widhts) - np.max(widhts)) // 2)\n",
    "    return np.asarray(images)\n",
    "\n",
    "train_images = load_images(train_paths)\n",
    "valid_images = load_images(valid_paths)\n",
    "test_images = load_images(test_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_combined_features(image, upper_limit=100000):\n",
    "    # SIFT Feature Extraction\n",
    "    sift = cv2.ORB_create()\n",
    "    keypoints_sift, descriptors_sift = sift.detectAndCompute(image, None)\n",
    "\n",
    "    # Akaze Feature Extraction\n",
    "    akaze = cv2.AKAZE_create()\n",
    "    keypoints_akaze, descriptors_akaze = akaze.detectAndCompute(image, None)\n",
    "\n",
    "    # Handle None descriptors by replacing with zeros\n",
    "    if descriptors_sift is None:\n",
    "        descriptors_sift = np.zeros((1, 128))  # SIFT descriptors are 128-dimensional\n",
    "    if descriptors_akaze is None:\n",
    "        descriptors_akaze = np.zeros((1, 32))   # akaze descriptors are 32-dimensional\n",
    "\n",
    "    # Flatten and concatenate features\n",
    "    combined_features = np.concatenate(\n",
    "        [descriptors_sift.flatten(), descriptors_akaze.flatten()]\n",
    "    )\n",
    "\n",
    "    # Adjust feature length to match upper_limit\n",
    "    if len(combined_features) > upper_limit:\n",
    "        # Truncate if features exceed the upper limit\n",
    "        combined_features = combined_features[:upper_limit]\n",
    "    elif len(combined_features) < upper_limit:\n",
    "        # Pad with zeros if features are less than the upper limit\n",
    "        padding_length = upper_limit - len(combined_features)\n",
    "        combined_features = np.pad(combined_features, (0, padding_length), mode='constant')\n",
    "\n",
    "    return np.asarray(combined_features)\n",
    "\n",
    "combined_features = []\n",
    "for image in train_images:\n",
    "    feature = extract_combined_features(image)\n",
    "    combined_features.append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def match_keypoints_between_images(image1, image2):\n",
    "    # Preprocess images\n",
    "    preprocessed1 = preprocess_image(image1)\n",
    "    preprocessed2 = preprocess_image(image2)\n",
    "\n",
    "    # Extract features\n",
    "    combined_features1, keypoints1, _ = extract_combined_features(preprocessed1)\n",
    "    combined_features2, keypoints2, _ = extract_combined_features(preprocessed2)\n",
    "\n",
    "    # Brute Force Matcher\n",
    "    sift = cv2.SIFT_create()\n",
    "    _, descriptors1 = sift.detectAndCompute(preprocessed1, None)\n",
    "    _, descriptors2 = sift.detectAndCompute(preprocessed2, None)\n",
    "    matcher = cv2.BFMatcher(cv2.NORM_L2, crossCheck=False)\n",
    "\n",
    "    # Match descriptors and apply Lowe's ratio test\n",
    "    raw_matches = matcher.knnMatch(descriptors1, descriptors2, k=2)\n",
    "    good_matches = [m for m, n in raw_matches if m.distance < 0.75 * n.distance]\n",
    "\n",
    "    return keypoints1, keypoints2, good_matches\n",
    "\n",
    "def match_keypoints(desc1, desc2):\n",
    "    bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
    "    matches = bf.match(desc1, desc2)\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(features, labels):\n",
    "    scaler = StandardScaler()\n",
    "    encoder = LabelEncoder()\n",
    "    labels = encoder.fit_transform(labels)\n",
    "    # Split dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "    # Train an SVM classifier\n",
    "    model = XGBClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict and evaluate\n",
    "    predictions = model.predict(X_test)\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, predictions))\n",
    "    return model\n",
    "\n",
    "model = train_classifier(combined_features, train_paths['class'].values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
