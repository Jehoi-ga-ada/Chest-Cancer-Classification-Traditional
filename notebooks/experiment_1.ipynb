{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persyaratan Teknis:\n",
    "- Gunakan minimal dua operator pengolahan citra dasar (misalnya,\n",
    "Gaussian blur, edge detection) untuk meningkatkan kualitas data.\n",
    "- Implementasikan minimal dua metode detektor atau deskriptor fitur lokal\n",
    "(misalnya, SIFT, SURF, ORB).\n",
    "- Buat sistem untuk menemukan korespondensi antara beberapa citra\n",
    "(misalnya, menggunakan keypoints matching) dan menerapkannya dalam\n",
    "pengenalan.\n",
    "- Bangun sistem pengenalan berbasis fitur yang mampu mengklasifikasikan\n",
    "atau mengidentifikasi objek dalam citra secara otomatis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = Path('../dataset/Data')\n",
    "\n",
    "train_paths = pd.read_csv(DATASET_PATH / \"train_paths.csv\")\n",
    "valid_paths = pd.read_csv(DATASET_PATH / \"valid_paths.csv\")\n",
    "test_paths = pd.read_csv(DATASET_PATH / \"test_paths.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@17.792] global loadsave.cpp:241 findDecoder imread_('dataset/Data/train/adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib/000046 (5).png'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) /io/opencv/modules/imgproc/src/resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 23\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;66;03m# heights.append(np.shape(image)[0])\u001b[39;00m\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;66;03m# widhts.append(np.shape(image)[1])\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m# print((np.min(heights) - np.max(heights)) // 2)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# print((np.min(widhts) - np.max(widhts)) // 2)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(images)\n\u001b[0;32m---> 23\u001b[0m train_images \u001b[38;5;241m=\u001b[39m \u001b[43mload_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_paths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m valid_images \u001b[38;5;241m=\u001b[39m load_images(valid_paths)\n\u001b[1;32m     25\u001b[0m test_images \u001b[38;5;241m=\u001b[39m load_images(test_paths)\n",
      "Cell \u001b[0;32mIn[7], line 14\u001b[0m, in \u001b[0;36mload_images\u001b[0;34m(annotation)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m annotation[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues:\n\u001b[1;32m     13\u001b[0m     image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(path, flags\u001b[38;5;241m=\u001b[39mcv2\u001b[38;5;241m.\u001b[39mIMREAD_GRAYSCALE)\n\u001b[0;32m---> 14\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     image \u001b[38;5;241m=\u001b[39m preprocess_image(image)\n\u001b[1;32m     16\u001b[0m     images\u001b[38;5;241m.\u001b[39mappend(image)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.10.0) /io/opencv/modules/imgproc/src/resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n"
     ]
    }
   ],
   "source": [
    "def preprocess_image(image): # all good \n",
    "    # Apply Gaussian Blur\n",
    "    blurred = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "    # Apply Edge Detection (Canny)\n",
    "    edges = cv2.Canny(blurred, 100, 200)\n",
    "    return edges\n",
    "\n",
    "def load_images(annotation): # all good\n",
    "    images = []\n",
    "    # heights = []\n",
    "    # widhts = []\n",
    "    for path in annotation['path'].values:\n",
    "        image = cv2.imread(path, flags=cv2.IMREAD_GRAYSCALE)\n",
    "        image = cv2.resize(image, (256, 256))\n",
    "        image = preprocess_image(image)\n",
    "        images.append(image)\n",
    "        # heights.append(np.shape(image)[0])\n",
    "        # widhts.append(np.shape(image)[1])\n",
    "    # print((np.min(heights) - np.max(heights)) // 2)\n",
    "    # print((np.min(widhts) - np.max(widhts)) // 2)\n",
    "    return np.array(images)\n",
    "\n",
    "train_images = load_images(train_paths)\n",
    "valid_images = load_images(valid_paths)\n",
    "test_images = load_images(test_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import cv2\n",
    "\n",
    "# Step 1: Extract Features Using Both SIFT and ORB\n",
    "def extract_combined_features(images):\n",
    "    sift = cv2.SIFT_create()\n",
    "    orb = cv2.ORB_create()\n",
    "    combined_features = []\n",
    "    \n",
    "    for image in tqdm(images, desc=\"Extracting SIFT + ORB features\"):\n",
    "        # Extract SIFT features\n",
    "        _, sift_descriptors = sift.detectAndCompute(image, None)\n",
    "        sift_descriptors = sift_descriptors if sift_descriptors is not None else np.zeros((1, 128))\n",
    "\n",
    "        # Extract ORB features\n",
    "        _, orb_descriptors = orb.detectAndCompute(image, None)\n",
    "        orb_descriptors = orb_descriptors if orb_descriptors is not None else np.zeros((1, 32))\n",
    "\n",
    "        # Concatenate descriptors\n",
    "        combined_descriptors = np.hstack([\n",
    "            np.resize(sift_descriptors, (len(sift_descriptors), 128)),  # Ensure fixed length\n",
    "            np.resize(orb_descriptors, (len(orb_descriptors), 32))     # Ensure fixed length\n",
    "        ])\n",
    "        combined_features.append(combined_descriptors)\n",
    "    \n",
    "    return combined_features\n",
    "\n",
    "# Step 2: Create Bag of Visual Words (BoVW) for Combined Features\n",
    "def create_bovw_features(features, n_clusters=100):\n",
    "    # Combine all descriptors for clustering\n",
    "    all_descriptors = np.vstack(features)\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    kmeans.fit(all_descriptors)\n",
    "    \n",
    "    # Create histogram representation for each image\n",
    "    bovw_features = []\n",
    "    for descriptors in tqdm(features, desc=\"Creating BoVW features\"):\n",
    "        histogram = np.zeros(n_clusters)\n",
    "        if descriptors is not None:\n",
    "            cluster_labels = kmeans.predict(descriptors)\n",
    "            for label in cluster_labels:\n",
    "                histogram[label] += 1\n",
    "        bovw_features.append(histogram)\n",
    "    return np.array(bovw_features), kmeans\n",
    "\n",
    "# Step 3: Prepare Data\n",
    "train_features_combined = extract_combined_features(train_images)\n",
    "valid_features_combined = extract_combined_features(valid_images)\n",
    "test_features_combined = extract_combined_features(test_images)\n",
    "\n",
    "train_bovw, kmeans = create_bovw_features(train_features_combined, n_clusters=150)\n",
    "valid_bovw, _ = create_bovw_features(valid_features_combined, kmeans.n_clusters)\n",
    "test_bovw, _ = create_bovw_features(test_features_combined, kmeans.n_clusters)\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "train_bovw = scaler.fit_transform(train_bovw)\n",
    "valid_bovw = scaler.transform(valid_bovw)\n",
    "test_bovw = scaler.transform(test_bovw)\n",
    "\n",
    "# Step 4: Train Classifier\n",
    "labels = train_paths['label']  # Assuming the labels are in a column named 'label'\n",
    "clf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "clf.fit(train_bovw, labels)\n",
    "\n",
    "# Step 5: Evaluate\n",
    "valid_preds = clf.predict(valid_bovw)\n",
    "valid_labels = valid_paths['label']\n",
    "print(\"Validation Classification Report:\")\n",
    "print(classification_report(valid_labels, valid_preds))\n",
    "\n",
    "test_preds = clf.predict(test_bovw)\n",
    "test_labels = test_paths['label']\n",
    "print(\"Test Classification Report:\")\n",
    "print(classification_report(test_labels, test_preds))\n",
    "\n",
    "# Step 6: Visualization\n",
    "def plot_sample_predictions(images, labels, preds, num_samples=5):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for i in range(num_samples):\n",
    "        plt.subplot(1, num_samples, i + 1)\n",
    "        plt.imshow(images[i], cmap='gray')\n",
    "        plt.title(f\"True: {labels[i]}\\nPred: {preds[i]}\")\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "plot_sample_predictions(test_images, test_labels, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Combine SIFT and ORB Features\n",
    "def extract_combined_features(image, upper_limit=None):\n",
    "    # SIFT Feature Extraction\n",
    "    sift = cv2.SIFT_create(nfeatures=200)\n",
    "    keypoints_sift, descriptors_sift = sift.detectAndCompute(image, None)\n",
    "\n",
    "    # ORB Feature Extraction\n",
    "    orb = cv2.ORB_create(nfeatures=200)\n",
    "    keypoints_orb, descriptors_orb = orb.detectAndCompute(image, None)\n",
    "\n",
    "    # Handle None descriptors\n",
    "    if descriptors_sift is None:\n",
    "        descriptors_sift = np.zeros((1, 128))\n",
    "    if descriptors_orb is None:\n",
    "        descriptors_orb = np.zeros((1, 32))\n",
    "\n",
    "    if len(descriptors_sift) > 0:\n",
    "        norms_sift = np.linalg.norm(descriptors_sift, axis=1, keepdims=True)\n",
    "        descriptors_sift = descriptors_sift / (norms_sift + 1e-7)  # Avoid division by zero\n",
    "\n",
    "    # Flatten and concatenate\n",
    "    combined_features = np.concatenate(\n",
    "        [descriptors_sift.flatten(), descriptors_orb.flatten()]\n",
    "    )\n",
    "\n",
    "    # Ensure fixed size (upper_limit) by padding or truncating\n",
    "    if upper_limit == None:\n",
    "        return combined_features\n",
    "    elif len(combined_features) < upper_limit:\n",
    "        combined_features = np.pad(combined_features, (0, upper_limit - len(combined_features)))\n",
    "    else:\n",
    "        combined_features = combined_features[:upper_limit]\n",
    "\n",
    "    return combined_features\n",
    "\n",
    "# Step 2: Extract Features from Dataset\n",
    "def extract_features(images, upper_limit=400):\n",
    "    features = []\n",
    "    for image in images:\n",
    "        combined_features = extract_combined_features(image, upper_limit)\n",
    "        features.append(combined_features)\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Example labels for training images\n",
    "train_labels = train_paths['class'].values \n",
    "valid_labels = valid_paths['class'].values \n",
    "test_labels = test_paths['class'].values \n",
    "\n",
    "# Step 1: Prepare the matcher\n",
    "def create_matcher(matcher_type=\"BF\"):\n",
    "    if matcher_type == \"FLANN\":\n",
    "        index_params = dict(algorithm=1, trees=5)  # FLANN parameters\n",
    "        search_params = dict(checks=50)  # Search parameters\n",
    "        matcher = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    elif matcher_type == \"BF\":\n",
    "        matcher = cv2.BFMatcher(cv2.NORM_L2, crossCheck=False)  # BFMatcher with L2 norm\n",
    "    else:\n",
    "        raise ValueError(\"Invalid matcher type. Choose 'FLANN' or 'BF'.\")\n",
    "    return matcher\n",
    "\n",
    "# Step 2: Classify an image\n",
    "def classify_image(image, train_features, train_labels, matcher_type=\"BF\", k=2):\n",
    "    matcher = create_matcher(matcher_type)\n",
    "    query_features = extract_combined_features(image).astype(np.float32)\n",
    "\n",
    "    # Match query features with each set of train features\n",
    "    best_label = None\n",
    "    best_index = 0\n",
    "    max_matches = 0\n",
    "\n",
    "    for i, train_feature in tqdm(enumerate(train_features)):\n",
    "        train_feature = train_feature.astype(np.float32)\n",
    "        matches = matcher.match(query_features.reshape(-1, 1), train_feature.reshape(-1, 1))\n",
    "\n",
    "        # Count the number of good matches\n",
    "        good_matches = [m for m in matches if m.distance < 0.7 * max(m.distance for m in matches)]\n",
    "\n",
    "        # Update best match\n",
    "        if len(good_matches) > max_matches:\n",
    "            max_matches = len(good_matches)\n",
    "            best_index = i\n",
    "            best_label = train_labels[i]\n",
    "\n",
    "    return best_label, best_index\n",
    "\n",
    "# Step 3: Testing Classification\n",
    "# Assuming you already have `train_features` extracted from your training set\n",
    "train_features = extract_features(train_images)\n",
    "valid_features = extract_features(valid_images)\n",
    "test_features = extract_features(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3a72a1ac6294c4eb59bad0812dd7f7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: large.cell.carcinoma\n"
     ]
    }
   ],
   "source": [
    "# from random import randint\n",
    "# random_idx = randint(0, len(test_paths)-1)\n",
    "# test_label = test_paths.iloc[random_idx, 1]\n",
    "# test_image = test_images[random_idx]  # Replace with any test image\n",
    "# predicted_label, match_img_idx = classify_image(test_image, train_features, train_labels, matcher_type=\"BF\")\n",
    "# print(f\"True label: {test_label}\")\n",
    "# print(f\"Predicted label: {predicted_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine train and validation sets for final training\n",
    "X_train = np.vstack((train_features, valid_features))\n",
    "y_train = np.hstack((train_labels, valid_labels))\n",
    "\n",
    "# Use test features for evaluation\n",
    "X_test = test_features\n",
    "y_test = test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.526984126984127\n",
      "Classification Report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "         adenocarcinoma       0.48      0.78      0.59       120\n",
      "   large.cell.carcinoma       0.37      0.14      0.20        51\n",
      "                 normal       0.82      0.87      0.85        54\n",
      "squamous.cell.carcinoma       0.41      0.21      0.28        90\n",
      "\n",
      "               accuracy                           0.53       315\n",
      "              macro avg       0.52      0.50      0.48       315\n",
      "           weighted avg       0.50      0.53      0.48       315\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Create the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, rf_predictions))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, rf_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.43174603174603177\n",
      "SVM Classification Report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "         adenocarcinoma       0.46      0.53      0.49       120\n",
      "   large.cell.carcinoma       0.12      0.10      0.11        51\n",
      "                 normal       0.53      0.87      0.66        54\n",
      "squamous.cell.carcinoma       0.42      0.23      0.30        90\n",
      "\n",
      "               accuracy                           0.43       315\n",
      "              macro avg       0.38      0.43      0.39       315\n",
      "           weighted avg       0.41      0.43      0.40       315\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "svm_predictions = svm_model.predict(X_test)\n",
    "\n",
    "print(\"SVM Accuracy:\", accuracy_score(y_test, svm_predictions))\n",
    "print(\"SVM Classification Report:\\n\", classification_report(y_test, svm_predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
